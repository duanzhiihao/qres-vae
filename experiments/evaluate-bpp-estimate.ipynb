{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\libraries\\anaconda3\\envs\\pt112env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, OrderedDict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as tvf\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "sys.path.append('../')\n",
    "from models.library import qres34m\n",
    "from models.qresvae import pad_divisible_by\n",
    "device = torch.device('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, dataset_root):\n",
    "    device = next(model.parameters()).device\n",
    "    img_paths = list(Path(dataset_root).rglob('*.*'))\n",
    "    img_paths.sort()\n",
    "\n",
    "    all_image_stats = defaultdict(float)\n",
    "    pbar = tqdm(img_paths)\n",
    "    for impath in pbar:\n",
    "        # read image\n",
    "        img = Image.open(impath)\n",
    "        imgh, imgw = img.height, img.width\n",
    "        img_padded = pad_divisible_by(img, div=64)\n",
    "        im = tvf.to_tensor(img_padded).unsqueeze_(0).to(device=device)\n",
    "\n",
    "        stats = model.forward_eval(im, return_rec=True)\n",
    "        im_hat = stats['im_hat']\n",
    "        bpp_estimateed = float(stats['bppix']) * (im.shape[2]*im.shape[3]) / (imgh * imgw)\n",
    "\n",
    "        model.compress_file(impath, 'tmp.bits')\n",
    "        num_bits = Path('tmp.bits').stat().st_size * 8\n",
    "\n",
    "        # compute psnr\n",
    "        real = np.array(img).astype(np.float32) / 255.0\n",
    "        fake = im_hat.cpu().squeeze(0).permute(1,2,0)[:imgh, :imgw, :].numpy()\n",
    "        mse = np.square(real - fake).mean()\n",
    "        stats = {\n",
    "            'psnr': float(-10 * np.log10(mse)),\n",
    "            'bpp' : num_bits / (imgh * imgw),\n",
    "            'bpp-estimated': bpp_estimateed\n",
    "        }\n",
    "        # accumulate stats\n",
    "        all_image_stats['count'] += 1\n",
    "        for k,v in stats.items():\n",
    "            all_image_stats[k] += float(v)\n",
    "        # logging\n",
    "        msg = ', '.join([f'{k}={float(v):.3f}' for k,v in stats.items()])\n",
    "        pbar.set_description(f'image {impath.stem}: {msg}')\n",
    "\n",
    "    # average over all images\n",
    "    count = all_image_stats.pop('count')\n",
    "    results = {k: v/count for k,v in all_image_stats.items()}\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate(root):\n",
    "    weights_root = Path('../checkpoints/qres34m')\n",
    "    # save_json_path = 'results/tmp-qres34m.json'\n",
    "\n",
    "    all_lmb_stats = defaultdict(list)\n",
    "    for lmb in [16, 32, 64, 128, 256, 512, 1024, 2048]:\n",
    "        # initialize model\n",
    "        model = qres34m(lmb=lmb)\n",
    "\n",
    "        wpath = weights_root / f'lmb{lmb}/last_ema.pt'\n",
    "        msd = torch.load(wpath)['model']\n",
    "        model.load_state_dict(msd)\n",
    "\n",
    "        print(f'Evaluating lmb={lmb}. Model weights={wpath}')\n",
    "        model.compress_mode()\n",
    "        model = model.cuda()\n",
    "        model.eval()\n",
    "\n",
    "        results = evaluate_model(model, root)\n",
    "        # print(results)\n",
    "        for k,v in results.items():\n",
    "            all_lmb_stats[k].append(v)\n",
    "\n",
    "        # save to json\n",
    "        # with open(save_json_path, 'w') as f:\n",
    "        #     json.dump(all_lmb_stats, fp=f, indent=4)\n",
    "\n",
    "    for k, vlist in all_lmb_stats.items():\n",
    "        vlist_str = ' & '.join([f'{v:.12f}'[:7] for v in vlist])\n",
    "        print(f'{k:<6s} = [{vlist_str}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=16. Model weights=..\\checkpoints\\qres34m\\lmb16\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=28.858, bpp=0.287, bpp-estimated=0.282: 100%|██████████| 24/24 [00:04<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=32. Model weights=..\\checkpoints\\qres34m\\lmb32\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=30.925, bpp=0.449, bpp-estimated=0.444: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=64. Model weights=..\\checkpoints\\qres34m\\lmb64\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=33.226, bpp=0.643, bpp-estimated=0.639: 100%|██████████| 24/24 [00:04<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=128. Model weights=..\\checkpoints\\qres34m\\lmb128\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=35.362, bpp=0.913, bpp-estimated=0.909: 100%|██████████| 24/24 [00:04<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=256. Model weights=..\\checkpoints\\qres34m\\lmb256\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=37.556, bpp=1.253, bpp-estimated=1.248: 100%|██████████| 24/24 [00:04<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=512. Model weights=..\\checkpoints\\qres34m\\lmb512\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=39.634, bpp=1.629, bpp-estimated=1.624: 100%|██████████| 24/24 [00:04<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=1024. Model weights=..\\checkpoints\\qres34m\\lmb1024\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=41.516, bpp=2.147, bpp-estimated=2.143: 100%|██████████| 24/24 [00:04<00:00,  5.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=2048. Model weights=..\\checkpoints\\qres34m\\lmb2048\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image kodim24: psnr=43.426, bpp=2.785, bpp-estimated=2.780: 100%|██████████| 24/24 [00:04<00:00,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr   = [30.0210 & 31.9801 & 33.8986 & 36.1126 & 38.1649 & 40.2613 & 42.2478 & 44.3549]\n",
      "bpp    = [0.18352 & 0.30125 & 0.45200 & 0.67388 & 0.95406 & 1.28697 & 1.74814 & 2.35659]\n",
      "bpp-estimated = [0.17960 & 0.29680 & 0.44780 & 0.66960 & 0.94993 & 1.28291 & 1.74430 & 2.35219]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate('d:/datasets/improcessing/kodak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=16. Model weights=..\\checkpoints\\qres34m\\lmb16\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=32.175, bpp=0.067, bpp-estimated=0.067: 100%|██████████| 30/30 [00:42<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=32. Model weights=..\\checkpoints\\qres34m\\lmb32\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=34.253, bpp=0.109, bpp-estimated=0.109: 100%|██████████| 30/30 [00:43<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=64. Model weights=..\\checkpoints\\qres34m\\lmb64\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=35.739, bpp=0.161, bpp-estimated=0.160: 100%|██████████| 30/30 [00:44<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=128. Model weights=..\\checkpoints\\qres34m\\lmb128\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=37.658, bpp=0.259, bpp-estimated=0.259: 100%|██████████| 30/30 [00:44<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=256. Model weights=..\\checkpoints\\qres34m\\lmb256\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=39.489, bpp=0.409, bpp-estimated=0.410: 100%|██████████| 30/30 [00:44<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=512. Model weights=..\\checkpoints\\qres34m\\lmb512\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=41.394, bpp=0.611, bpp-estimated=0.612: 100%|██████████| 30/30 [00:43<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=1024. Model weights=..\\checkpoints\\qres34m\\lmb1024\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=43.096, bpp=0.941, bpp-estimated=0.942: 100%|██████████| 30/30 [00:46<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating lmb=2048. Model weights=..\\checkpoints\\qres34m\\lmb2048\\last_ema.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 8019e85654193a14b938689e3cf06b790d39197eb5a57f9de83f7b58d2e3302c: psnr=45.010, bpp=1.430, bpp-estimated=1.434: 100%|██████████| 30/30 [00:43<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psnr   = [30.6719 & 32.7126 & 34.1318 & 36.2879 & 38.2443 & 40.2436 & 42.1072 & 44.0814]\n",
      "bpp    = [0.15405 & 0.24315 & 0.35457 & 0.54065 & 0.79773 & 1.10183 & 1.55027 & 2.14379]\n",
      "bpp-estimated = [0.15370 & 0.24236 & 0.35435 & 0.54013 & 0.79785 & 1.10251 & 1.55179 & 2.14681]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate('d:/datasets/improcessing/clic/test-2022')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pt112env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7011b38e07ec2da0d01422c79c574946d8a01efe9f84b7c651d5bba01f4b044"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
