{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms.functional as tvf\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from models.library import qres17m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "# initialize model\n",
    "lmb = 64\n",
    "model = qres17m(lmb=lmb)\n",
    "wpath = f'../checkpoints/qres17m/lmb{lmb}/last_ema.pt'\n",
    "msd = torch.load(wpath)['model']\n",
    "model.load_state_dict(msd)\n",
    "\n",
    "model = model.to(device=device)\n",
    "model.eval()\n",
    "print(f'Using lmb={lmb}. Model weights={wpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impath1 = Path('../images/celaba64-1.png')\n",
    "impath2 = Path('../images/celaba64-2.png')\n",
    "\n",
    "im1 = tvf.to_tensor(Image.open(impath1)).unsqueeze_(0).to(device=device)\n",
    "im2 = tvf.to_tensor(Image.open(impath2)).unsqueeze_(0).to(device=device)\n",
    "\n",
    "stats1 = model.forward_get_latents(im1)\n",
    "stats1 = [st['z'] for st in stats1]\n",
    "stats2 = model.forward_get_latents(im2)\n",
    "stats2 = [st['z'] for st in stats2]\n",
    "# samples = model.forward_samples_set_latents(1, latents=stats1)\n",
    "\n",
    "steps = 8\n",
    "interpolations = []\n",
    "linspace = torch.linspace(0, 1, steps).tolist()\n",
    "L = len(stats1)\n",
    "for keep in range(1, L+1):\n",
    "    interpolations.append(im1.squeeze(0))\n",
    "    for lmb in linspace:\n",
    "        latents = [(1-lmb)*z1 + lmb*z2 for z1, z2 in zip(stats1, stats2)]\n",
    "        latents = [z if (i < keep) else None for (i,z) in enumerate(latents)]\n",
    "        sample = model.cond_sample(latents, nhw_repeat=(1,1,1), temprature=0.)\n",
    "        interpolations.append(sample.squeeze(0))\n",
    "    interpolations.append(im2.squeeze(0))\n",
    "\n",
    "svpath = f'runs/adv_interpolation_{impath1.stem}_{impath2.stem}.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = tv.utils.make_grid(interpolations, nrow=steps+2)\n",
    "tvf.to_pil_image(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pt112env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7011b38e07ec2da0d01422c79c574946d8a01efe9f84b7c651d5bba01f4b044"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
